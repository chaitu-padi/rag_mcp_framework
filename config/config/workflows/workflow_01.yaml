
data_ingestion:
  datasource:
    type: oracle
    params:
      user: system
      password: PULL FROM ENV:ORACLE_PASS
      host: localhost
      port: 1521
      service_name: FREEPDB1
      table: fin_ana_data
  vectordb:
    type: ChromaDB
    params:
      persist_directory: ./chromadb
  embedding:
    type: sentence-transformers
    params:
      model: all-MiniLM-L6-v2
      chunk_size: 512
      max_batch_size: 5461
llm_inference:
  llm:
    type: OpenAI
    params:
      model: gpt-4o-mini
      max_tokens: 512
      temperature: 0.7
      top_p: 1.0
      api_key: "PULL FROM ENV:OPENAI_API_KEY"
    # RAG pipeline query configuration
  query:
    top_k: 1000  # Number of top documents to use for context (default: 10 if not set)
  mcp:
    enabled: true
    fallback_to_vectordb: false  # If true, fallback to vector DB if MCP context is empty. If false, do not fallback.
    tools:
      - name: "oracle_query"
        description: "Query Oracle DB using Model Context Protocol"
        datasource: "oracle"
        params:
          user: "system"
          password: "PULL FROM ENV:ORACLE_PASS"
          host: "localhost"
          port: 1521
          service_name: "FREEPDB1"
          query: "SELECT * FROM FIN_ANA_DATA FETCH FIRST 5 ROWS ONLY"
          fetch_size: 100
  prompts:
    default: |
      Context:
      {context}
      
      Question: {question}
      Answer:
    concise: |
      Given the following context, answer concisely:
      {context}
      Q: {question}
      A:
    variables:
      tool: MCP
      user_role: analyst

# Optional: pipeline steps for reference
pipeline:
  type: rag
  steps:
    - datasource
    - embedding
    - vectordb
    - mcp
    - llm
